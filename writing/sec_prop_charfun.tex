\subsection{The characteristic function and related quantities}

The \textit{characteristic function} is a central tool in studying probability distributions. In this section, we review general results about the characteristic function of a multivariate continuous distribution. Let $X$ be a random vector in $\Rp$. The characteristic function of $X$ is the function $\zeta : \Rp \rightarrow \C$ given by
\begin{equation*}
    \zeta(t) = \expec{}{\expf{it^\top X}}.
\end{equation*}
The characteristic function is an essential tool in studying distributions. Indeed, the following theorem shows that under regularity conditions on the characteristic function, the density of a random vector exists and can be expressed in terms of the characteristic function.

\begin{theorem} \label{thm-char-inversion}
    Let $X \sim P$ be a random vector in $\Rp$ with characteristic function $\zeta \in L^1(\Rp)$. Then, the density of $X$ exists and is given by
    \begin{equation} \label{eq-density-via-charfun}
        f(x) = \left(2\pi\right)^{-p} \intRp{t}{ \expf{-it^\top x}\zeta(t) }.
    \end{equation}
\end{theorem}

\begin{proof}
    Let $A \subset \Rp$ be a bounded rectangle $A = [a_1, b_1] \times \ldots \times [a_p, b_p]$ with $P(X \in \partial A) = 0$. By Theorem 3.10.4 in \cite{durrett_2019}, we have that
    \begin{equation*}
        P(X \in A) = \lim_{T \rightarrow \infty} \left(2\pi\right)^{-p}\int_{\left[-T, T\right]^p} \zeta(t) \prod_{k=1}^p \frac{\expf{-it_k a_k} - \expf{-it_k b_k}}{i t_k} \d t.
    \end{equation*}
    By rewriting various terms under the integral, one obtains
    \begin{align*}
        P(X \in A) 
        &= \lim_{T \rightarrow \infty} \left(2\pi\right)^{-p}\int_{\left[-T, T\right]^p} \zeta(t) \prod_{k=1}^p \frac{\expf{-it_k a_k} - \expf{-it_k b_k}}{i t_k} \d t \\
        &= \lim_{T \rightarrow \infty} \left(2\pi\right)^{-p}\int_{\left[-T, T\right]^p} \zeta(t) \prod_{k=1}^p \int_{a_k}^{b_k}\expf{-i t_k x_k} \d x_k \d t \\
        &= \lim_{T \rightarrow \infty} \left(2\pi\right)^{-p}\int_{\left[-T, T\right]^p} \zeta(t) \int_A \expf{-i t^\top x} \d x \d t.
    \end{align*}
    Since $\zeta \in L^1(\Rp)$ and $A$ is bounded, the integrand in the previous equation is integrable, and the limit $T \rightarrow \infty$ can be replaced by the proper integral over $\Rp$. Further, using the absolute convergence property of $\zeta$, Fubini's Theorem allows us to change the order of integration and gives us
    \begin{align*}
        P(X \in A) 
        &= \left(2\pi\right)^{-p}\intRp{t}{\int_A \zeta(t) \expf{-i t^\top x} \d x} \\
        &= \int_A \left(2\pi\right)^{-p} \intRp{t}{\zeta(t) \expf{-i t^\top x} } \d x.
    \end{align*}
    By definition, this shows that the density of $X$ exists and is given by (\ref{eq-density-via-charfun}).
\end{proof}

If $X$ has a density function, the characteristic function of $X$ corresponds to the Fourier transform of its density. Taking this generalized view of Fourier transforms will allow us to study approximations of densities that are not necessarily densities and characteristic functions themselves. We will use a less commonly used definition of the Fourier transform, in which the sign of the exponent is reversed. For $f \in L^1(\Rp)$, the Fourier transform $\F[f]$ is the function given by
\begin{equation} \label{eq-fourier-density}
    \F[f](t) = \int_\Rp \expf{it^\top x}f(x)\d x \ \ \ \ \ \ \t{for all } t \in \Rp.
\end{equation}

In this context, we can generalize Theorem \ref{thm-char-inversion} to provide the necessary conditions under which the Fourier transform can be inverted.

\begin{corollary} \label{corr-fourier-inv}
    Suppose that $f \in L^1(\Rp)$ and $\zeta \in L^1(\Rp)$ are related by
    \begin{equation}\label{eq-fourier-trans}
        \zeta(t) = \F[f](t) \ \ \ \ \ \ \t{for all } t \in \Rp.
    \end{equation}
    Then, for any $x \in \Rp$, it holds that
    \begin{equation} \label{eq-fourier-inv}
        f(x) = \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \zeta(t) \d t.
    \end{equation}
\end{corollary}

\begin{proof}
    We decompose $f$ in positive and negative parts by $f(x) = f^+(x) - f^-(x)$ where $f^+(x) = f(x) \mathbb{1}_{f(x) \geq 0}$ and $f^-(x) = -f(x) \mathbb{1}_{f(x) < 0}$. Then, if $c^+ = \int_\Rp f^+(x) \d x$ and $c^- = \int_\Rp f^-(x) \d x$, the functions $f^+ / c^+$ and $f^- / c^-$ are both densities over $\Rp$ with resepctive characteristic function $\zeta^+$ and $\zeta^-$. We can replace these quantities in (\ref{eq-fourier-trans}) to have
    \begin{align*}
        \zeta(t) 
        &= \int_\Rp \expf{it^\top x}f(x)\d x \\
        &= c^+ \int_\Rp \expf{it^\top x} \frac{1}{c^+}f^+(x)\d x - c^- \int_\Rp \expf{it^\top x} \frac{1}{c^-}f^-(x)\d x\\
        &= c^+ \zeta^+(t) - c^-\zeta^-(t).
    \end{align*}
    By applying Theorem \ref{thm-char-inversion} to the positive and negative parts of $f$, we obtain that
    \begin{equation*}
        \frac{1}{c^\pm} f^\pm(x) = \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \zeta^\pm(t) \d t,
    \end{equation*}
    and hence
    \begin{align*}
        f(x) 
        &= f^+(x) - f^-(x) \\
        &= c^+ \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \zeta^+(t) \d t
         - c^- \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \zeta^-(t) \d t \\
        &= \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \left[ c^+\zeta^+(t) - c^-\zeta^-(t)\right] \d t\\
        &= \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \zeta(t) \d t. \qedhere
    \end{align*}
\end{proof}

This corollary lets us extend the notation introduced in (\ref{eq-fourier-density}) and define the inverse Fourier transform operator $\Finv$ as in (\ref{eq-fourier-inv}),
\begin{equation*}
    \Finv[\zeta](x) = \left(2\pi\right)^{-p}\int_\Rp \expf{-i t^\top x} \zeta(t) \d t.
\end{equation*}

In order to better understand the characteristic function, we need to be able to know in which functional space it lies. The following lemma relates $L^p$ integrability of the characteristic function to the existence of the density of a convolution of random variables.

\input{thm-char-integrable-convolution}

In the following sections, we study approximations of the characteristic function in terms of its Taylor approximation. As one might expect, computing the Fourier and inverse Fourier transforms of such approximations involves computing the Fourier transforms of derivatives of the characteristic function. Before studying Fourier transforms of differential quantities, we introduce some notation for multivariate derivatives.

For $k \in \N$, we define $S_p(k)$ as the set of index vectors of length $k$ over $p$-dimensional vectors, that is,
\begin{equation*}
    S_p(k) = \left\{ (s_1, \ldots, s_k) : s_i \in [p] \right\},
\end{equation*}
where $[p] = \eset{1, \ldots, p}$. Let $f : \Rp \rightarrow \R$ be a $k$-times differentiable function, $s \in S_p(k)$ and $x_0 \in \Rp$, then the \textit{$s$-derivative} of $f$ in $x_0$ is given by
\begin{equation*}
    D^s f(x_0) = \frac{\d^k}{\d x_{s_1} \ldots \d x_{s_k}} f(x) \bigg|_{x=x_0}.
\end{equation*}

We now proceed to the following lemma, which gives a simple expression of the Fourier transform of derivatives of a function.

\begin{lemma} \label{lemma-fourier-derivative}
    Let $r \in \N$ and $f \in L^1(\Rp)$ such that all partial derivatives of $f$ of order up to $r$ exist, and for any $\tilde{s} \in S_p(r-1)$,
    \begin{equation} \label{eq-tails-to-zero}
        \lim_{\norm{x} \rightarrow \infty} \expf{it^\top x}D^{\tilde{s}}f(x) = 0.
    \end{equation}
    Then for any $s \in S_p(r)$, it holds that
    \begin{equation*}
        \F\left[D^s f \right](t) = (-i)^r t^s \F[f].
    \end{equation*}
\end{lemma}
\begin{proof}
    Let $\tilde{s} = (s_1, \ldots, s_{r-1})$, then by direct computation of the Fourier transform,
    \begin{align*}
        \F\left[D^s f \right](t) 
        &= (2\pi)^{-p}\intRp{x}{ \expf{it^\top x} D^s f(x) } \\
        &= (2\pi)^{-p}\int_{\R^{-1}} \int_\R 
            \expf{it^\top x} \ddx{x_{s_r}} D^{\tilde{s}} f(x) 
        \d x_{s_r} \d x_{\tilde{s}}\,.
    \end{align*}
    Integrating by part over the axis $x_{s_r}$ and using Assumption (\ref{eq-tails-to-zero}) gives,
    \begin{align*}
        \F\left[D^s f \right](t)  
        &= - (2\pi)^{-p}\intRp{x}{
            (it_{s_r})\expf{it^\top x} D^{\tilde{s}} f(x)
        } \\
        &= -it_{s_r} (2\pi)^{-p}\intRp{x}{
            \expf{it^\top x} D^{\tilde{s}} f(x)
        } \\
        &= -it_{s_r} \F\left[D^{\tilde{s}} f \right](t)
    \end{align*}
    Iterating the previous steps completes the proof.
\end{proof}

Next, we introduce the \textit{cumulant generating function}, a quantity related to the characteristic function that is easier to manipulate. For a random vector $X$ in $\Rp$, the cumulant generating function of $X$ is the function $K : \Rp \rightarrow \R$ given by
\begin{equation*}
    K(t) = \log \expec{}{\expf{t^\top X}}.
\end{equation*}

The derivatives of the cumulant generating function are called the \textit{cumulants}. Let $s \in S_p(k)$ be an index vector of length $k$, then if the involved derivatives exist, we define the $s$-cumulant of $X$ as
\begin{equation*}
    \kappa_s = D^s K(0).
\end{equation*}
In the rest of the thesis, the cumulants might depend on various quantities (sample size, variable of interest, parameters of a distribution, $\ldots$) in which case we will use variations of this notation to make clear which cumulants are being discussed.

Since the Normal distribution will often be used in the rest of the thesis, the next example gives the cumulant  generating function and cumulants of a multivarite Normal distribution.
\begin{example} \label{ex-cumulants-mvn}
    Let $X \sim N(\mu, \Sigma)$ with $\mu \in \Rp$ and $\Sigma \in \Sp$, then the cumulant generating function $K(t; \mu, \Sigma)$ of $X$ is the quadratic function given by
    \begin{equation*}
        K(t; \mu, \Sigma) = t^\top\mu + t^\top\Sigma t.
    \end{equation*}
    It is then clear that all cumulants of $X$ exist, where first order cumulants are the components $\mu$, second order cumulants are the components of $\Sigma$, and cumulants of higher order are 0.
\end{example}

We now state without a proof some simple properties of cumulants that will be useful in future proofs.
\begin{lemma} \label{lem-cumulants-props}
    Let $X_1, \ldots, X_n \simiid P$, then the following holds for any $s \in S(k)$
    \begin{itemize}
        \item {
        $\kappa_s(X_1 + \ldots + X_n) = n\kappa_s(X_1)$
        }
        \item {
            For all $c \in \R$, $\kappa_s(c X_1) = c^k\kappa_s(X_1)$
        }
        \item {
            For all $c \in \Rp$, $\kappa_s(X_1 + c) =
            \begin{cases}
                \kappa_s(X_1) + c_i &\text{if}\ s=(i)\\
                \kappa_s(X_1)& \text{otherwise}
            \end{cases}$,
        }
    \end{itemize}
    where $\kappa_s(Z)$ is the $s$-cumulant of the random variable $Z$.
\end{lemma}

One can see that the cumulant generating function is closely related to the characteristic function since
\begin{equation*}
    K(t) 
    = \log \expec{}{\expf{t^\top X}} 
    = \log \expec{}{\expf{i (-i)t^\top X}}
    = \log \zeta(-it).
\end{equation*}
This equality also allows us to define the cumulants $\kappa_s$ for $s \in S_p(k)$ in terms of the characteristic function
\begin{equation*}
    \kappa_s = D^s K(0) 
    = \frac{\d^k}{\d x_{s_1} \ldots \d x_{s_k}} \log \zeta(-it) \bigg|_{t=0}
    = (-i)^{k} D^s \log \zeta(0),
\end{equation*}
and hence
\begin{equation*}
    D^s \log \zeta(0) = i^k \kappa_s.
\end{equation*}